## Learning to Control End Effector Poses with PPO and SAC

_**Haomiao Zhang**, University of British Columbia_

End effector pose control is crucial in the industriesfor various tasks. To control end effector poses, inverse kinematicsusually  would  be  applied  to  decompose  poses  to  joint  positionsfor joint level control. While inverse kinematics is effective whenthe joint dimension low, it becomes difficult and time consumingWith  the  increase  of  joint  dimension.  Fortunately,  deep  rein-forcement  learning  (DRL)  has  demonstrated  its  capability  inperforming  motion  control  with  high  joint  dimension.  In  thispaper, controllers are learned using PPO and SAC to control theend effector poses throuhgh inverse kinematics and joint positioncontrol. Training and evaluation are performed on a IIWA robotarm  in  PyBullet  simulation.  With  the  given  training  time  andhyperparameters, the DRL controllers perform statistically betterthan  PD  controller  when  reaching  the  same  target,  but  theperformance  decreases  when  trying  to  reach  different  targetswithin  the  the  work  envelope.
